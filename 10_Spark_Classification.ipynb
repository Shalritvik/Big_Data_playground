{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOTTUBSncY0c",
        "outputId": "c1fbf627-1e66-47dc-806d-32be4a3b4dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .master ('local[*]')\\\n",
        "        .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "Gkh5epTkdv4x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK0PzwHJeclB",
        "outputId": "dbd7c3e7-61e6-41d9-e845-5eb81fd500a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/BigDataColab25FallShalRitvikSinha\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ZB53F9fnEP",
        "outputId": "a09121c2-4c34-4a15-821e-94e34da61752"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/BigDataColab25FallShalRitvikSinha\n",
            " 10.Spark-ClassificationShalRitvikSinha.ipynb\n",
            "'6. MR-WordCountReducer_Shal_Ritvik_Sinha.ipynb'\n",
            " 7.Spark-WordCountShal_Ritvik_Sinha.ipynb\n",
            " 8.Spark-SQLShalRitvikSinha.ipynb\n",
            " 8.Spark-StreamingShalRitvikSinha.ipynb\n",
            " 9.Spark-Handling-missing-values.ShalRitvikSinha.ipynb\n",
            " ad-clicks.csv.gz\n",
            " Alice.txt\n",
            " BigDataShalRitvikSinhaTest1.ipynb\n",
            " BigDataShalRitvikSinhaTest2.ipynb\n",
            " buy-clicks.csv.gz\n",
            " Cheshire\n",
            " daily_weather.csv\n",
            " game-clicks.csv.gz\n",
            " hadoop-3.3.6\n",
            " hadoop-3.3.6.tar.gz\n",
            " hadoop-3.3.6.tar.gz.1\n",
            " join1_FileA.txt\n",
            " join1_FileB.txt\n",
            " join1_mapper.py\n",
            " join1_reducer.py\n",
            " join2_genchanA.txt\n",
            " join2_genchanB.txt\n",
            " join2_genchanc.txt\n",
            " join2_gennumA.txt\n",
            " join2_gennumB.txt\n",
            " join2_gennumC.txt\n",
            " join2_mapper.py\n",
            " join2_reducer.py\n",
            " make_join2data.py\n",
            " MT\n",
            " MT1_B\n",
            " MT2\n",
            " MT3\n",
            " MT_Q1_make_data.py\n",
            " MT_Q2_make_data.py\n",
            " MT_Q3_make_data.py\n",
            " out0\n",
            " out_4Data_Join\n",
            " out_4WC\n",
            " outDataJoin2\n",
            " out_Quiz3\n",
            " out_wordmedian\n",
            " Shal_Ritvik_Sinha_Mid-term.ipynb\n",
            "'Shal Ritvik Sinha_MT_Q1_A.txt'\n",
            "'Shal Ritvik Sinha_MT_Q1_B.txt'\n",
            " SparkOutPut\n",
            " testfile1\n",
            " testfile2\n",
            " Text3.txt\n",
            " wordcount_mapper.py\n",
            " wordcount_reducer.py\n",
            " words2.txt\n",
            " words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import DataFrameNaFunctions\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import Binarizer\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer"
      ],
      "metadata": {
        "id": "d5LYkEdlfp49"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.load('/content/drive/My Drive/BigDataColab25FallShalRitvikSinha/daily_weather.csv',format='com.databricks.spark.csv',header='true', inferSchema='true' )\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AHcGCmjgc4H",
        "outputId": "9ad9f959-509a-40c0-ef5b-66c33e8449cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['number',\n",
              " 'air_pressure_9am',\n",
              " 'air_temp_9am',\n",
              " 'avg_wind_direction_9am',\n",
              " 'avg_wind_speed_9am',\n",
              " 'max_wind_direction_9am',\n",
              " 'max_wind_speed_9am',\n",
              " 'rain_accumulation_9am',\n",
              " 'rain_duration_9am',\n",
              " 'relative_humidity_9am',\n",
              " 'relative_humidity_3pm']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "featureColumns = ['air_pressure_9am' , 'air_temp_9am', 'avg_wind_direction_9am' , 'avg_wind_speed_9am',\n",
        "'max_wind_direction_9am' , 'max_wind_speed_9am' , 'rain_accumulation_9am','rain_duration_9am']"
      ],
      "metadata": {
        "id": "pouRXacohNxu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('number')"
      ],
      "metadata": {
        "id": "ECoLJiPdh257"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =df.na.drop()"
      ],
      "metadata": {
        "id": "trz9MAuih60B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count(), len(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYlMQ4QLiKBR",
        "outputId": "27ef6386-a806-4df6-f1c4-c2136d00e5d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1064, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer = Binarizer(threshold=24.99999, inputCol=\"relative_humidity_3pm\", outputCol=\"label\")\n",
        "binarizedDF = binarizer.transform(df)"
      ],
      "metadata": {
        "id": "Apwj6NjNiOCv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binarizedDF.select(\"relative_humidity_3pm\",\"label\").show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM2EY1mWiZZk",
        "outputId": "49c68317-49de-4845-fa8c-0ca1d283d308"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----+\n",
            "|relative_humidity_3pm|label|\n",
            "+---------------------+-----+\n",
            "|   36.160000000000494|  1.0|\n",
            "|     19.4265967985621|  0.0|\n",
            "|   14.460000000000045|  0.0|\n",
            "|   12.742547353761848|  0.0|\n",
            "+---------------------+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
        "assembled = assembler.transform(binarizedDF)"
      ],
      "metadata": {
        "id": "35WoAaTLjOgT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = assembled.randomSplit([0.8,0.2], seed = 13234 )"
      ],
      "metadata": {
        "id": "hwf9TTqqjXS9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData.count(), testData.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWCb_IZ7jicY",
        "outputId": "d8cf1a2a-7b2f-429c-edf0-7e4115593a36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(846, 218)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5,\n",
        "minInstancesPerNode=20, impurity=\"gini\")"
      ],
      "metadata": {
        "id": "_oqdYKeDnqVY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[dt])\n",
        "model = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "SR5Eroagn4Cp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions =model.transform(testData)"
      ],
      "metadata": {
        "id": "f8lrznrVoXVn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select(\"prediction\", \"label\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VojNBwhnoc0Y",
        "outputId": "8ca3bcea-5113-45ce-c0b6-0e4bd6ec33c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|prediction|label|\n",
            "+----------+-----+\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       0.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       0.0|  0.0|\n",
            "|       1.0|  1.0|\n",
            "+----------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select(\"prediction\", \"label\").write.save(path='/content/drive/My Drive/BigDataColab25FallShalRitvikSinha/predictions.csv', format='com.databricks.spark.csv',\n",
        "header='true' )"
      ],
      "metadata": {
        "id": "lqGZAhLwok3y"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}