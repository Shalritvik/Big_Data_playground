{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOTTUBSncY0c",
        "outputId": "fdffbbc3-234f-4cca-848f-e20fbed0328f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .master ('local[*]')\\\n",
        "        .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "Gkh5epTkdv4x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK0PzwHJeclB",
        "outputId": "bedf44f0-ccc7-4072-ae5a-f272433751c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/BigDataColab25FallShalRitvikSinha\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9ZB53F9fnEP",
        "outputId": "904ac1bd-ddc7-4950-effd-e0b370568d0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/BigDataColab25FallShalRitvikSinha\n",
            " 10.Spark-ClassificationShalRitvikSinha.ipynb\n",
            " 11_2.Spark-Classifier-evaluationShalRitvikSinha.ipynb\n",
            "'6. MR-WordCountReducer_Shal_Ritvik_Sinha.ipynb'\n",
            " 7.Spark-WordCountShal_Ritvik_Sinha.ipynb\n",
            " 8.Spark-SQLShalRitvikSinha.ipynb\n",
            " 8.Spark-StreamingShalRitvikSinha.ipynb\n",
            " 9.Spark-Handling-missing-values.ShalRitvikSinha.ipynb\n",
            " ad-clicks.csv.gz\n",
            " Alice.txt\n",
            " BigDataShalRitvikSinhaTest1.ipynb\n",
            " BigDataShalRitvikSinhaTest2.ipynb\n",
            " buy-clicks.csv.gz\n",
            " Cheshire\n",
            " daily_weather.csv\n",
            " game-clicks.csv.gz\n",
            " hadoop-3.3.6\n",
            " hadoop-3.3.6.tar.gz\n",
            " hadoop-3.3.6.tar.gz.1\n",
            " join1_FileA.txt\n",
            " join1_FileB.txt\n",
            " join1_mapper.py\n",
            " join1_reducer.py\n",
            " join2_genchanA.txt\n",
            " join2_genchanB.txt\n",
            " join2_genchanc.txt\n",
            " join2_gennumA.txt\n",
            " join2_gennumB.txt\n",
            " join2_gennumC.txt\n",
            " join2_mapper.py\n",
            " join2_reducer.py\n",
            " make_join2data.py\n",
            " MT\n",
            " MT1_B\n",
            " MT2\n",
            " MT3\n",
            " MT_Q1_make_data.py\n",
            " MT_Q2_make_data.py\n",
            " MT_Q3_make_data.py\n",
            " out0\n",
            " out_4Data_Join\n",
            " out_4WC\n",
            " outDataJoin2\n",
            " out_Quiz3\n",
            " out_wordmedian\n",
            " predictions.csv\n",
            " Shal_Ritvik_Sinha_Mid-term.ipynb\n",
            "'Shal Ritvik Sinha_MT_Q1_A.txt'\n",
            "'Shal Ritvik Sinha_MT_Q1_B.txt'\n",
            " SparkOutPut\n",
            " testfile1\n",
            " testfile2\n",
            " Text3.txt\n",
            " wordcount_mapper.py\n",
            " wordcount_reducer.py\n",
            " words2.txt\n",
            " words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import DataFrameNaFunctions\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import Binarizer\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer"
      ],
      "metadata": {
        "id": "d5LYkEdlfp49"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.read.load('/content/drive/My Drive/BigDataColab25FallShalRitvikSinha/daily_weather.csv',format='com.databricks.spark.csv',header='true', inferSchema='true' )\n",
        "\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AHcGCmjgc4H",
        "outputId": "5ad5f64a-403f-44b8-afa8-ae883766b2c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['number',\n",
              " 'air_pressure_9am',\n",
              " 'air_temp_9am',\n",
              " 'avg_wind_direction_9am',\n",
              " 'avg_wind_speed_9am',\n",
              " 'max_wind_direction_9am',\n",
              " 'max_wind_speed_9am',\n",
              " 'rain_accumulation_9am',\n",
              " 'rain_duration_9am',\n",
              " 'relative_humidity_9am',\n",
              " 'relative_humidity_3pm']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark: What values are in the number column?"
      ],
      "metadata": {
        "id": "i1hSGsvBfG4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBMV9LegdFxG",
        "outputId": "9dd4a7db-7a8c-4315-8bc2-1e7e828970ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- number: integer (nullable = true)\n",
            " |-- air_pressure_9am: double (nullable = true)\n",
            " |-- air_temp_9am: double (nullable = true)\n",
            " |-- avg_wind_direction_9am: double (nullable = true)\n",
            " |-- avg_wind_speed_9am: double (nullable = true)\n",
            " |-- max_wind_direction_9am: double (nullable = true)\n",
            " |-- max_wind_speed_9am: double (nullable = true)\n",
            " |-- rain_accumulation_9am: double (nullable = true)\n",
            " |-- rain_duration_9am: double (nullable = true)\n",
            " |-- relative_humidity_9am: double (nullable = true)\n",
            " |-- relative_humidity_3pm: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"number\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhJ1VwKmqHsd",
        "outputId": "427eb3b1-de6e-4009-9c81-b241d20ec27a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|number|\n",
            "+------+\n",
            "|     0|\n",
            "|     1|\n",
            "|     2|\n",
            "|     3|\n",
            "|     4|\n",
            "|     5|\n",
            "|     6|\n",
            "|     7|\n",
            "|     8|\n",
            "|     9|\n",
            "|    10|\n",
            "|    11|\n",
            "|    12|\n",
            "|    13|\n",
            "|    14|\n",
            "|    15|\n",
            "|    16|\n",
            "|    17|\n",
            "|    18|\n",
            "|    19|\n",
            "+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(\"number\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSnp-Y_2qRiB",
        "outputId": "911bdf30-2817-47f7-b4ce-4c2d5dcd65c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|            number|\n",
            "+-------+------------------+\n",
            "|  count|              1095|\n",
            "|   mean|             547.0|\n",
            "| stddev|316.24357700987383|\n",
            "|    min|                 0|\n",
            "|    max|              1094|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark: With the original dataset split into 80% for training and 20% for test\n",
        "how many of the first 20 samples from the test set were correctly classified?"
      ],
      "metadata": {
        "id": "ndnlhfvWfFT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import DataFrameNaFunctions\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import Binarizer\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer"
      ],
      "metadata": {
        "id": "CJWgO6EWhrq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featureColumns = ['air_pressure_9am' , 'air_temp_9am', 'avg_wind_direction_9am' , 'avg_wind_speed_9am',\n",
        "'max_wind_direction_9am' , 'max_wind_speed_9am' , 'rain_accumulation_9am','rain_duration_9am']"
      ],
      "metadata": {
        "id": "3TACeJcihzSm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =df.na.drop()"
      ],
      "metadata": {
        "id": "7bNJKyTDdde1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer = Binarizer(threshold=24.99999, inputCol=\"relative_humidity_3pm\", outputCol=\"label\")\n",
        "binarizedDF = binarizer.transform(df)"
      ],
      "metadata": {
        "id": "Apwj6NjNiOCv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
        "assembled = assembler.transform(binarizedDF)"
      ],
      "metadata": {
        "id": "06GJ5hQEfDwL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = assembled.randomSplit([0.8,0.2], seed = 13234 )\n"
      ],
      "metadata": {
        "id": "ppnNeeh9e8uf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5,\n",
        "minInstancesPerNode=20, impurity=\"gini\")"
      ],
      "metadata": {
        "id": "zQjsGB-Nje9N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[dt])\n",
        "model = pipeline.fit(trainingData)"
      ],
      "metadata": {
        "id": "ITQCkxHBjxKx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions =model.transform(testData)"
      ],
      "metadata": {
        "id": "w4hQybcpj4sd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select(\"prediction\", \"label\").show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6ZLCQpFqjnO",
        "outputId": "bdda7df9-1c73-4eff-f1f3-e15d7ef60a0c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|prediction|label|\n",
            "+----------+-----+\n",
            "|       1.0|  1.0|\n",
            "|       0.0|  1.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  0.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  1.0|\n",
            "|       1.0|  0.0|\n",
            "|       0.0|  0.0|\n",
            "+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_20 = predictions.select(\"prediction\", \"label\").limit(20)\n",
        "correct_count = first_20.filter(first_20.prediction == first_20.label).count()\n",
        "print(correct_count)\n"
      ],
      "metadata": {
        "id": "JzyzAIdvj55J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d4bc4e-4cc4-4e56-e3ca-15039792ae0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we split the data using 70% for training data and 30% for test data, how\n",
        "many samples would the training set have (using seed 13234)?"
      ],
      "metadata": {
        "id": "Ktkkn_h7duz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed=13234)\n",
        "training_count = trainingData.count()\n"
      ],
      "metadata": {
        "id": "o8FCy4ljdvJn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEmzdUKMdx6c",
        "outputId": "2d296ab2-0eaa-406c-ed0f-610acf8ff2d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "731\n"
          ]
        }
      ]
    }
  ]
}